

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Neural Networks &mdash; Machine Learning Interview Questions 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/theme_overrides.css" />

  
    <link rel="canonical" href="https://mkareshk.github.io/ml-interview/markdowns/Neural%20Networks.html" />
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=d45e8c67"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Optimization Algorithms" href="Optimization%20Algorithms.html" />
    <link rel="prev" title="Natural Language Processing" href="Natural%20Language%20Processing.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Machine Learning Interview Questions
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Active%20Learning.html">Active Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Anomaly%20Detection.html">Anomaly Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="Attention%20Mechanisms.html">Attention Mechanisms</a></li>
<li class="toctree-l1"><a class="reference internal" href="Bayesian%20Inference.html">Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="Bayesian%20Neural%20Networks.html">Bayesian Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Clustering%20Algorithms.html">Clustering Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="Convolutional%20Neural%20Networks.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Cross-Validation%20Techniques.html">Cross-Validation Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="Decision%20Trees.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="Dimensionality%20Reduction.html">Dimensionality Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Ensemble%20Methods.html">Ensemble Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="Ethics%20in%20Machine%20Learning.html">Ethics in Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Feature%20Engineering.html">Feature Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="Federated%20Learning.html">Federated Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Generative%20Adversarial%20Networks.html">Generative Adversarial Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Gradient%20Descent%20Variants.html">Gradient Descent Variants</a></li>
<li class="toctree-l1"><a class="reference internal" href="Graphical%20Models.html">Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="Hyperparameter%20Tuning.html">Hyperparameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Interpretability%20and%20Explainability.html">Interpretability and Explainability</a></li>
<li class="toctree-l1"><a class="reference internal" href="K-Nearest%20Neighbors.html">K-Nearest Neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="Linear%20Regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="Logistic%20Regression.html">Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="Markov%20Decision%20Processes.html">Markov Decision Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="Meta-Learning.html">Meta-Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Model%20Evaluation%20Metrics.html">Model Evaluation Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="Naive%20Bayes.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="Natural%20Language%20Processing.html">Natural Language Processing</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Optimization%20Algorithms.html">Optimization Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="Quantum%20Machine%20Learning.html">Quantum Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Random%20Forests.html">Random Forests</a></li>
<li class="toctree-l1"><a class="reference internal" href="Recurrent%20Neural%20Networks.html">Recurrent Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Reinforcement%20Learning.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Self-Supervised%20Learning.html">Self-Supervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Semi-Supervised%20Learning.html">Semi-Supervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Supervised%20Learning.html">Supervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Support%20Vector%20Machines.html">Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="Time%20Series%20Analysis.html">Time Series Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="Transfer%20Learning.html">Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Unsupervised%20Learning.html">Unsupervised Learning</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Machine Learning Interview Questions</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Neural Networks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/markdowns/Neural Networks.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="neural-networks">
<h1>Neural Networks<a class="headerlink" href="#neural-networks" title="Link to this heading"></a></h1>
<hr class="docutils" />
<p><strong>Question:</strong> Discuss the implications of overparameterization on the training dynamics of deep neural networks.</p>
<p><strong>Answer:</strong>
Overparameterization in deep neural networks refers to having more parameters than necessary to fit the training data. This can lead to several interesting dynamics during training:</p>
<ol class="arabic simple">
<li><p><strong>Optimization:</strong> Overparameterized networks often have a smoother loss landscape, making it easier for gradient-based methods to find a global or near-global minimum. This is because the network can use its excess capacity to find multiple solutions that fit the data.</p></li>
<li><p><strong>Generalization:</strong> Surprisingly, overparameterized networks can generalize well despite fitting training data perfectly, a phenomenon known as the “double descent” curve. Initially, as model complexity increases, generalization error decreases, then increases, and finally decreases again.</p></li>
<li><p><strong>Implicit Regularization:</strong> Stochastic Gradient Descent (SGD) tends to implicitly favor simpler models, even in overparameterized settings, due to its noise-induced regularization effects.</p></li>
</ol>
<p>For example, in a linear model <span class="math notranslate nohighlight">\(y = Xw\)</span>, overparameterization occurs when <span class="math notranslate nohighlight">\(w\)</span> has more dimensions than <span class="math notranslate nohighlight">\(X\)</span>’s rank, yet SGD often finds the minimum norm solution, which generalizes well.</p>
<hr class="docutils" />
<p><strong>Question:</strong> What are the trade-offs between depth and width in neural network architectures for specific tasks?</p>
<p><strong>Answer:</strong>
In neural networks, depth refers to the number of layers, while width refers to the number of neurons per layer. Increasing depth allows the network to learn more complex hierarchical features, which is beneficial for tasks like image recognition. However, deeper networks are harder to train due to issues like vanishing gradients, which can be mitigated using techniques like residual connections.</p>
<p>On the other hand, increasing width can improve the network’s ability to capture more features at each layer, potentially improving performance on tasks requiring rich feature representations. However, wider networks require more computational resources and can lead to overfitting if not properly regularized.</p>
<p>Mathematically, deeper networks can approximate more complex functions due to their hierarchical structure, as described by the Universal Approximation Theorem. However, the choice between depth and width should be guided by the specific task, data availability, and computational constraints. For instance, a task with limited data may benefit from a shallower, wider network to prevent overfitting.</p>
<hr class="docutils" />
<p><strong>Question:</strong> How do skip connections in residual networks address the vanishing gradient problem?</p>
<p><strong>Answer:</strong>
Skip connections in residual networks, introduced by He et al. in ResNet, help mitigate the vanishing gradient problem by allowing gradients to flow more easily through the network. In a traditional deep network, gradients can diminish as they are backpropagated through many layers, leading to slow or stalled learning.</p>
<p>Skip connections create shortcut paths by adding the input of a layer to its output, forming a residual block. Mathematically, if <span class="math notranslate nohighlight">\(x\)</span> is the input and <span class="math notranslate nohighlight">\(F(x)\)</span> is the learned residual mapping, the output is <span class="math notranslate nohighlight">\(y = F(x) + x\)</span>. This identity mapping ensures that gradients can bypass the non-linear transformations and directly propagate backward through the network.</p>
<p>This mechanism effectively preserves the gradient magnitude, enabling deeper networks to be trained effectively and addressing the vanishing gradient problem. Empirically, this has led to the successful training of networks with hundreds or even thousands of layers.</p>
<hr class="docutils" />
<p><strong>Question:</strong> What are the effects of different weight initialization strategies on neural network convergence?</p>
<p><strong>Answer:</strong>
Weight initialization significantly affects neural network convergence by influencing the starting point of optimization. Poor initialization can lead to vanishing or exploding gradients, especially in deep networks, hindering convergence.</p>
<p>For instance, initializing weights to zero causes symmetry breaking issues, where neurons learn the same features. Random initialization helps, but if values are too large, gradients can explode; if too small, they can vanish.</p>
<p>Xavier initialization addresses this by setting weights based on the number of input and output units, specifically <span class="math notranslate nohighlight">\(\text{Var}(w) = \frac{2}{n_{in} + n_{out}}\)</span>, to maintain the variance of activations across layers. He initialization, <span class="math notranslate nohighlight">\(\text{Var}(w) = \frac{2}{n_{in}}\)</span>, is tailored for ReLU activations, preventing dying ReLU problems.</p>
<p>Proper initialization accelerates convergence, improves training stability, and enhances model performance by maintaining a balanced flow of gradients during backpropagation.</p>
<hr class="docutils" />
<p><strong>Question:</strong> How does the choice of activation function influence the learnability and convergence of deep neural networks?</p>
<p><strong>Answer:</strong>
The choice of activation function significantly influences the learnability and convergence of deep neural networks. Activation functions introduce non-linearity, allowing networks to learn complex patterns. Common choices include sigmoid, tanh, and ReLU.</p>
<p>Sigmoid and tanh can suffer from vanishing gradient problems, where gradients become too small for effective learning, especially in deep networks. This can lead to slow convergence or getting stuck in local minima.</p>
<p>ReLU, defined as <span class="math notranslate nohighlight">\(f(x) = \max(0, x)\)</span>, mitigates this by allowing gradients to flow more effectively, promoting faster convergence and deeper network training. However, ReLU can suffer from “dying ReLU” where neurons stop updating. Variants like Leaky ReLU and ELU address this by allowing small negative gradients.</p>
<p>The choice affects the optimization landscape, impacting how easily a network can learn from data and converge to a good solution. Thus, selecting an appropriate activation function is crucial for the performance of deep neural networks.</p>
<hr class="docutils" />
<p><strong>Question:</strong> Analyze the challenges of training very deep networks and the role of skip connections in addressing them.</p>
<p><strong>Answer:</strong>
Training very deep networks presents challenges such as vanishing and exploding gradients, where gradients become too small or too large during backpropagation, hindering effective learning. This occurs because gradients are multiplied through many layers, leading to numerical instability. Additionally, deeper networks are prone to overfitting and require more data and computational resources.</p>
<p>Skip connections, introduced in architectures like ResNet, address these issues by allowing gradients to flow more directly through the network. They create shortcut paths that bypass one or more layers, effectively implementing the identity function. Mathematically, if a layer’s output is <span class="math notranslate nohighlight">\(F(x)\)</span>, a skip connection adds the input <span class="math notranslate nohighlight">\(x\)</span>, resulting in <span class="math notranslate nohighlight">\(F(x) + x\)</span>. This structure helps maintain gradient magnitude, facilitating training of deeper networks. Skip connections also promote feature reuse and mitigate the vanishing gradient problem, enabling networks to learn more complex functions without degradation in performance.</p>
<hr class="docutils" />
<p><strong>Question:</strong> Discuss the theoretical underpinnings of neural network pruning and its impact on model capacity.</p>
<p><strong>Answer:</strong>
Neural network pruning involves reducing the number of parameters in a network by removing weights or neurons that contribute little to the model’s output. Theoretically, pruning is based on the observation that many parameters in over-parameterized networks are redundant.</p>
<p>The impact of pruning on model capacity can be understood through the lens of the VC (Vapnik–Chervonenkis) dimension, which measures the capacity of a model to fit a variety of functions. Pruning reduces the VC dimension, potentially lowering the model’s capacity to overfit, thus improving generalization.</p>
<p>Mathematically, consider a neural network with parameters <span class="math notranslate nohighlight">\(\theta\)</span>. Pruning leads to a new parameter set <span class="math notranslate nohighlight">\(\theta'\)</span>, where <span class="math notranslate nohighlight">\(||\theta'|| &lt; ||\theta||\)</span>. While this reduces capacity, it can enhance performance by eliminating noise and focusing on essential features.</p>
<p>Empirically, pruned networks often achieve similar accuracy with fewer resources, as shown in techniques like weight pruning and neuron pruning, which remove unimportant weights or entire neurons, respectively.</p>
<hr class="docutils" />
<p><strong>Question:</strong> Discuss the implications of weight initialization strategies on convergence rates in neural network training.</p>
<p><strong>Answer:</strong>
Weight initialization is crucial for the convergence of neural networks. Poor initialization can lead to vanishing or exploding gradients, impeding learning. For instance, if weights are too small, gradients vanish as they propagate backward, slowing convergence. Conversely, large weights can cause gradients to explode, leading to unstable updates.</p>
<p>He initialization, designed for ReLU activations, scales weights by <span class="math notranslate nohighlight">\(\sqrt{\frac{2}{n_{\text{in}}}}\)</span>, where <span class="math notranslate nohighlight">\(n_{\text{in}}\)</span> is the number of input units. This helps maintain variance across layers, facilitating efficient gradient flow.</p>
<p>Xavier initialization, suitable for sigmoid or tanh activations, scales weights by <span class="math notranslate nohighlight">\(\sqrt{\frac{1}{n_{\text{in}} + n_{\text{out}}}}\)</span>. This balances the variance between inputs and outputs, preventing saturation.</p>
<p>Proper initialization ensures that the network starts in a region of the parameter space conducive to rapid convergence, reducing the number of training epochs needed and improving the likelihood of reaching a good local minimum.</p>
<hr class="docutils" />
<p><strong>Question:</strong> What is the impact of batch normalization on internal covariate shift and model training dynamics?</p>
<p><strong>Answer:</strong>
Batch normalization (BN) addresses the internal covariate shift, which is the change in the distribution of network activations due to parameter updates during training. By normalizing the inputs of each layer to have zero mean and unit variance, BN stabilizes the learning process. This normalization is followed by a learnable linear transformation to maintain the representational power of the network.</p>
<p>Mathematically, for a mini-batch <span class="math notranslate nohighlight">\(\{x_1, x_2, \ldots, x_m\}\)</span>, BN computes:</p>
<div class="math notranslate nohighlight">
\[\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu_B\)</span> and <span class="math notranslate nohighlight">\(\sigma_B^2\)</span> are the mini-batch mean and variance, and <span class="math notranslate nohighlight">\(\epsilon\)</span> is a small constant for numerical stability. The normalized output <span class="math notranslate nohighlight">\(\hat{x}_i\)</span> is then scaled and shifted using parameters <span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>:</p>
<div class="math notranslate nohighlight">
\[y_i = \gamma \hat{x}_i + \beta\]</div>
<p>BN improves training dynamics by allowing higher learning rates, reducing sensitivity to initialization, and acting as a regularizer, often reducing the need for dropout.</p>
<hr class="docutils" />
<p><strong>Question:</strong> How does neural network interpretability impact model trustworthiness and decision-making in critical applications?</p>
<p><strong>Answer:</strong>
Neural network interpretability is crucial for model trustworthiness, especially in critical applications like healthcare, finance, and autonomous systems. Interpretability allows stakeholders to understand how a model makes decisions, which is essential for ensuring that the model is reliable and free from biases. This understanding can be achieved through techniques like feature importance, saliency maps, or surrogate models.</p>
<p>In decision-making, interpretability aids in validating the model’s reasoning process, ensuring that it aligns with domain knowledge and ethical standards. For instance, in healthcare, understanding which features (e.g., symptoms or test results) influence a diagnosis can help clinicians trust the model’s recommendations.</p>
<p>Mathematically, interpretability can involve analyzing gradients, such as in saliency maps where the gradient of the output with respect to input features <span class="math notranslate nohighlight">\(\frac{\partial y}{\partial x_i}\)</span> highlights important features. Overall, interpretability fosters trust by providing transparency, enabling error detection, and facilitating regulatory compliance.</p>
<hr class="docutils" />
<p><strong>Question:</strong> What are the theoretical challenges in ensuring robustness of neural networks against adversarial perturbations?</p>
<p><strong>Answer:</strong>
Theoretical challenges in ensuring robustness of neural networks against adversarial perturbations include:</p>
<ol class="arabic simple">
<li><p><strong>Non-linearity and High Dimensionality</strong>: Neural networks are highly non-linear and operate in high-dimensional spaces, making it difficult to characterize and bound adversarial perturbations.</p></li>
<li><p><strong>Lack of Convexity</strong>: The optimization problem for finding adversarial examples is non-convex, complicating the derivation of guarantees for robustness.</p></li>
<li><p><strong>Trade-off with Accuracy</strong>: Improving robustness often leads to a trade-off with model accuracy on clean data, as seen in robust optimization frameworks.</p></li>
<li><p><strong>Generalization of Robustness</strong>: Ensuring robustness against a specific set of perturbations does not guarantee robustness against all possible perturbations.</p></li>
<li><p><strong>Computational Complexity</strong>: Verifying robustness can be computationally expensive, involving solving complex optimization problems.</p></li>
</ol>
<p>Mathematically, robustness can be framed as ensuring that for a model <span class="math notranslate nohighlight">\(f(x)\)</span>, small perturbations <span class="math notranslate nohighlight">\(\delta\)</span> do not change the output significantly, i.e., <span class="math notranslate nohighlight">\(f(x + \delta) \approx f(x)\)</span> for small <span class="math notranslate nohighlight">\(\|\delta\|\)</span>. Ensuring this property is challenging due to the reasons above.</p>
<hr class="docutils" />
<p><strong>Question:</strong> Analyze the implications of neural network depth on the convergence of gradient-based optimization.</p>
<p><strong>Answer:</strong>
The depth of a neural network significantly affects the convergence of gradient-based optimization methods. Deeper networks often suffer from the vanishing or exploding gradient problem. In backpropagation, gradients are propagated backward through the network layers. For very deep networks, gradients can become exponentially small (vanishing) or large (exploding), making it difficult to update weights effectively.</p>
<p>Mathematically, if <span class="math notranslate nohighlight">\(\sigma\)</span> is the activation function, the gradient of the loss <span class="math notranslate nohighlight">\(L\)</span> with respect to a weight in the <span class="math notranslate nohighlight">\(l\)</span>-th layer is <span class="math notranslate nohighlight">\(\frac{\partial L}{\partial W^l} = \frac{\partial L}{\partial a^l} \cdot \sigma'(z^l) \cdot a^{l-1}\)</span>, where <span class="math notranslate nohighlight">\(a^l\)</span> is the activation and <span class="math notranslate nohighlight">\(z^l\)</span> is the pre-activation. Repeated multiplication by <span class="math notranslate nohighlight">\(\sigma'(z^l)\)</span> can lead to gradients approaching zero or infinity.</p>
<p>Techniques like batch normalization, skip connections (ResNets), and careful initialization (e.g., Xavier or He initialization) help mitigate these issues, improving convergence in deep networks.</p>
<hr class="docutils" />
<p><strong>Question:</strong> How does the expressivity of neural networks relate to the universal approximation theorem?</p>
<p><strong>Answer:</strong>
The expressivity of neural networks is closely related to the Universal Approximation Theorem, which states that a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function on compact subsets of <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>, given appropriate activation functions. This theorem highlights the potential of neural networks to represent complex functions, making them powerful tools for a variety of tasks.</p>
<p>The expressivity of a neural network refers to its ability to approximate a wide range of functions. The Universal Approximation Theorem provides a theoretical foundation for this by showing that even simple networks can achieve high expressivity. However, practical considerations such as the number of neurons, network depth, and choice of activation function (e.g., sigmoid, ReLU) affect the network’s ability to approximate functions effectively. While the theorem assures the existence of an approximation, it does not address how to find it, which is a challenge in training neural networks.</p>
<hr class="docutils" />
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Natural%20Language%20Processing.html" class="btn btn-neutral float-left" title="Natural Language Processing" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Optimization%20Algorithms.html" class="btn btn-neutral float-right" title="Optimization Algorithms" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Moein Kareshk.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>